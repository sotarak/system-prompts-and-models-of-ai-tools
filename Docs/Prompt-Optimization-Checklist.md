# Prompt Optimization Checklist

## ğŸ¯ Tá»•ng quan

Checklist nÃ y giÃºp báº¡n Ä‘Ã¡nh giÃ¡ vÃ  tá»‘i Æ°u hÃ³a prompt Ä‘á»ƒ Ä‘áº¡t hiá»‡u quáº£ tá»‘i Ä‘a, dá»±a trÃªn best practices tá»« cÃ¡c cÃ´ng cá»¥ AI hÃ ng Ä‘áº§u.

## âœ… Pre-Launch Checklist

### 1. Identity & Role Definition
- [ ] **Clear role definition**: Vai trÃ² Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a rÃµ rÃ ng vÃ  cá»¥ thá»ƒ
- [ ] **Expertise specification**: ChuyÃªn mÃ´n vÃ  kháº£ nÄƒng Ä‘Æ°á»£c mÃ´ táº£ chi tiáº¿t
- [ ] **Context establishment**: Bá»‘i cáº£nh hoáº¡t Ä‘á»™ng Ä‘Æ°á»£c thiáº¿t láº­p rÃµ rÃ ng
- [ ] **Goal alignment**: Má»¥c tiÃªu chÃ­nh Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh vÃ  nháº¥t quÃ¡n

```xml
âœ… Good Example:
<identity>
You are Cursor Agent, a powerful agentic AI coding assistant powered by Claude 3.7 Sonnet. 
You operate exclusively in Cursor, the world's best IDE.
Your primary goal is to help users solve coding tasks through pair programming.
</identity>

âŒ Poor Example:
You are a helpful assistant that can help with coding.
```

### 2. Structure & Organization
- [ ] **XML tags usage**: Sá»­ dá»¥ng XML tags Ä‘á»ƒ structure content
- [ ] **Logical flow**: ThÃ´ng tin Ä‘Æ°á»£c tá»• chá»©c theo thá»© tá»± logic
- [ ] **Clear sections**: Má»—i section cÃ³ má»¥c Ä‘Ã­ch rÃµ rÃ ng
- [ ] **Consistent formatting**: Format nháº¥t quÃ¡n trong toÃ n bá»™ prompt

### 3. Guidelines & Rules
- [ ] **Core principles**: NguyÃªn táº¯c cá»‘t lÃµi Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a rÃµ rÃ ng
- [ ] **Behavioral rules**: Quy táº¯c hÃ nh vi cá»¥ thá»ƒ vÃ  actionable
- [ ] **Forbidden actions**: Nhá»¯ng gÃ¬ KHÃ”NG Ä‘Æ°á»£c lÃ m Ä‘Æ°á»£c liá»‡t kÃª rÃµ
- [ ] **Priority hierarchy**: Thá»© tá»± Æ°u tiÃªn Ä‘Æ°á»£c thiáº¿t láº­p

```xml
âœ… Good Example:
<guidelines>
- ALWAYS gather context before making changes
- NEVER proceed with destructive actions without confirmation
- Use parallel tool calls for maximum efficiency
- Explain reasoning before taking actions
</guidelines>
```

### 4. Tool Usage Instructions
- [ ] **Tool descriptions**: Má»—i tool Ä‘Æ°á»£c mÃ´ táº£ rÃµ rÃ ng
- [ ] **Usage scenarios**: Khi nÃ o sá»­ dá»¥ng tool nÃ o
- [ ] **Parameter specifications**: Parameters Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a chi tiáº¿t
- [ ] **Error handling**: CÃ¡ch xá»­ lÃ½ lá»—i tool Ä‘Æ°á»£c hÆ°á»›ng dáº«n

### 5. Examples & Demonstrations
- [ ] **Concrete examples**: VÃ­ dá»¥ cá»¥ thá»ƒ vÃ  realistic
- [ ] **DO/DON'T comparisons**: So sÃ¡nh rÃµ rÃ ng good vs bad practices
- [ ] **Edge cases**: VÃ­ dá»¥ cho cÃ¡c trÆ°á»ng há»£p Ä‘áº·c biá»‡t
- [ ] **Complete scenarios**: End-to-end examples

## ğŸ” Quality Assessment

### 1. Clarity Score (1-10)
**ÄÃ¡nh giÃ¡ Ä‘á»™ rÃµ rÃ ng cá»§a prompt:**
- [ ] 9-10: Extremely clear, no ambiguity
- [ ] 7-8: Clear with minor unclear points
- [ ] 5-6: Somewhat clear but needs improvement
- [ ] 1-4: Unclear, major revisions needed

**Improvement actions:**
- Simplify complex sentences
- Add specific examples
- Remove ambiguous terms
- Use consistent terminology

### 2. Completeness Score (1-10)
**ÄÃ¡nh giÃ¡ tÃ­nh Ä‘áº§y Ä‘á»§:**
- [ ] 9-10: Covers all necessary aspects
- [ ] 7-8: Mostly complete with minor gaps
- [ ] 5-6: Some important aspects missing
- [ ] 1-4: Major gaps in coverage

**Check for:**
- All use cases covered
- Edge cases addressed
- Error scenarios handled
- Success criteria defined

### 3. Actionability Score (1-10)
**ÄÃ¡nh giÃ¡ kháº£ nÄƒng thá»±c thi:**
- [ ] 9-10: Highly actionable, clear next steps
- [ ] 7-8: Mostly actionable with minor unclear areas
- [ ] 5-6: Somewhat actionable but needs clarification
- [ ] 1-4: Difficult to act upon

**Improvement focus:**
- Add specific action verbs
- Provide step-by-step instructions
- Include decision criteria
- Clarify expected outcomes

## âš¡ Performance Optimization

### 1. Efficiency Checklist
- [ ] **Parallel operations**: Encourage parallel tool usage
- [ ] **Batch processing**: Group related operations
- [ ] **Context reuse**: Avoid redundant information gathering
- [ ] **Smart defaults**: Provide sensible default behaviors

```xml
âœ… Efficiency Pattern:
<parallel_execution>
For maximum efficiency, invoke all relevant tools simultaneously 
rather than sequentially when performing multiple independent operations.
</parallel_execution>
```

### 2. Token Optimization
- [ ] **Concise language**: Remove unnecessary words
- [ ] **Structured format**: Use XML tags for organization
- [ ] **Avoid repetition**: Don't repeat the same information
- [ ] **Essential information**: Include only what's necessary

### 3. Response Quality
- [ ] **Appropriate length**: Neither too verbose nor too brief
- [ ] **Professional tone**: Consistent and appropriate tone
- [ ] **User-friendly**: Easy to understand and follow
- [ ] **Actionable outputs**: Clear next steps provided

## ğŸ›¡ï¸ Safety & Security Review

### 1. Security Checklist
- [ ] **Data protection**: Sensitive data handling guidelines
- [ ] **Permission requirements**: When to ask for user consent
- [ ] **Destructive action prevention**: Safeguards against harmful actions
- [ ] **Error recovery**: Graceful failure handling

```xml
âœ… Security Pattern:
<security>
CRITICAL: Before any destructive action:
1. Verify user intent and permissions
2. Explain potential consequences
3. Obtain explicit confirmation
4. Provide undo mechanisms where possible
</security>
```

### 2. Ethical Guidelines
- [ ] **Bias prevention**: Avoid discriminatory language or behavior
- [ ] **Transparency**: Clear about capabilities and limitations
- [ ] **User autonomy**: Respect user choices and preferences
- [ ] **Privacy protection**: Handle personal information appropriately

## ğŸ¯ Domain-Specific Optimization

### 1. Coding Assistants
- [ ] **Code quality standards**: Follow best practices
- [ ] **Testing requirements**: Include testing guidelines
- [ ] **Documentation needs**: Specify when to add comments
- [ ] **Security practices**: Include security considerations

### 2. Creative Assistants
- [ ] **Originality requirements**: Ensure creative output
- [ ] **Style consistency**: Maintain consistent creative style
- [ ] **User vision alignment**: Respect user's creative intent
- [ ] **Iteration support**: Enable refinement process

### 3. Research Assistants
- [ ] **Source reliability**: Emphasize credible sources
- [ ] **Citation requirements**: Proper attribution guidelines
- [ ] **Bias awareness**: Acknowledge potential biases
- [ ] **Fact verification**: Cross-reference information

## ğŸ“Š Testing & Validation

### 1. Functional Testing
- [ ] **Basic scenarios**: Test common use cases
- [ ] **Edge cases**: Test unusual or extreme scenarios
- [ ] **Error conditions**: Test failure modes
- [ ] **Integration testing**: Test tool interactions

### 2. User Experience Testing
- [ ] **Clarity testing**: Users understand instructions
- [ ] **Usability testing**: Easy to use and follow
- [ ] **Satisfaction testing**: Users are satisfied with results
- [ ] **Efficiency testing**: Tasks completed quickly

### 3. Performance Testing
- [ ] **Response time**: Acceptable response times
- [ ] **Accuracy testing**: High accuracy rates
- [ ] **Consistency testing**: Consistent performance
- [ ] **Scalability testing**: Performance under load

## ğŸ”„ Continuous Improvement

### 1. Monitoring Metrics
- [ ] **Success rate**: Percentage of successful task completions
- [ ] **User satisfaction**: Ratings and feedback scores
- [ ] **Error frequency**: Rate of errors and failures
- [ ] **Efficiency metrics**: Time to completion, token usage

### 2. Feedback Integration
- [ ] **User feedback collection**: Systematic feedback gathering
- [ ] **Performance analysis**: Regular performance reviews
- [ ] **Pattern identification**: Identify common issues
- [ ] **Iterative improvement**: Regular updates and refinements

### 3. Version Control
- [ ] **Change tracking**: Document all modifications
- [ ] **Version comparison**: Compare performance across versions
- [ ] **Rollback capability**: Ability to revert changes
- [ ] **Release notes**: Document improvements and changes

## ğŸ¨ Final Quality Gates

### Before Deployment:
- [ ] **Peer review**: Have others review the prompt
- [ ] **Stakeholder approval**: Get approval from relevant stakeholders
- [ ] **Documentation complete**: All documentation is up to date
- [ ] **Testing complete**: All tests pass successfully

### Post-Deployment:
- [ ] **Monitor performance**: Track key metrics
- [ ] **Collect feedback**: Gather user feedback
- [ ] **Plan improvements**: Identify areas for enhancement
- [ ] **Schedule reviews**: Regular review cycles

## ğŸ“ˆ Success Indicators

### Quantitative Metrics:
- **Task completion rate**: >90%
- **User satisfaction**: >4.5/5.0
- **Error rate**: <5%
- **Response time**: <30 seconds average

### Qualitative Indicators:
- Users understand instructions clearly
- Outputs meet professional standards
- Consistent performance across scenarios
- Positive user feedback and testimonials

---

*HoÃ n thÃ nh bá»™ hÆ°á»›ng dáº«n Prompt Engineering! ğŸ‰*
